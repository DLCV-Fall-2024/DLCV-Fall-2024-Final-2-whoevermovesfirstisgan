inputs:
  ref_prompt: "A dog, a pet cat and a dog near a forest."
  base_prompt: "A dog, a pet cat and a dog near a forest."
  negative_prompt: "girl, human, cartoon"
  custom_prompts:
    - "A <welsh_dog_1> <welsh_dog_2>, a <welsh_dog_1> <welsh_dog_2> and a <welsh_dog_1> <welsh_dog_2> near a forest."
    - "A <siberian_cat_1> <siberian_cat_2>, a <siberian_cat_1> <siberian_cat_2> and a <siberian_cat_1> <siberian_cat_2> near a forest."
    - "A <corgi_dog_1> <corgi_dog_2>, a <corgi_dog_1> <corgi_dog_2> and a <corgi_dog_1> <corgi_dog_2> near a forest."
  ref_image_path: "sam_input/dog_cat_dog.jpg"
  ref_mask_paths:
    - "sam_output/dog_cat_dog/cat_mask.png"
    - "sam_output/dog_cat_dog/dog6_mask.png"
    - "sam_output/dog_cat_dog/dog_mask.png"
  init_mask_from_points: False
  mask_center_points: 
    - [512, 512]
    - [356, 280]
  init_image_path: ~
  init_mask_path: ~       
  edlora_paths:
    - "experiments/ED-LoRA_ours/welsh_dog.pth"
    - "experiments/ED-LoRA_ours/siberian_cat.pth"
    - "experiments/ED-LoRA_ours/corgi_dog.pth"
  load_edlora: True
  lora_alpha: 0.5

outputs:
  outroot: "outputs/prompt2/refine_60_90"
  image_outdir: "inference_results"
  latents_outdir: "inverted_latents"
  self_attn_outdir: "self_attn"
  cross_attn_outdir: "cross_attn"
  feature_mask_outdir: "feature_mask"


base_model:
  sd_ckpt: "experiments/pretrained_models/chilloutmix"
  variant: ""

sd_t2i:
  height: 512
  width: 512
  guidance_scale: 7.5
  num_inference_steps: 200
  start_seed: 0
  batch_size: 4
  n_batches: 4
  verbose: True

attention_operations:
  attn_guidance_end: 60
  attn_guidance_interval: 1
  attn_guidance_weight: 10
  custom_attn_guidance_factor: 1.0

  processor_filter_guidance: '.*up_blocks\.1\.attentions\.0.*attn1.*'
  params_guidance: ["key"]
  processor_filter_mask: '.*up_blocks\.2\.attentions\.2.*attn1.*'
  params_mask: ['attention_probs']
  processor_filter_merge: '.*up_blocks.*'
  params_merge: ["feature_output"]
  processor_filter_view_sa: '.*up_blocks\.2\.attentions\.2.*attn1.*'
  params_view_sa: ["attention_probs"]      
  processor_filter_view_ca: '.*up_blocks\.2\.attentions\.1.*attn2.*'
  params_view_ca: ["attention_probs"]    

  mask_refinement_start: 60
  mask_refinement_end: 90
  mask_update_interval: 5
  mask_overlap_threshold: 0
  num_kmeans_init: 100
  rect_mask: False

  use_loss_mask: False
  visualization: True



